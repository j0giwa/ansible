#!/usr/bin/env python3

import requests
import re
from bs4 import BeautifulSoup

if __name__ == '__main__':

    session = requests.Session()
    selectWikiPage = input("Wikipedia-url:")

    if "wikipedia" in selectWikiPage:

        # Get all links from references section
        html = session.post(selectWikiPage)
        bsObj = BeautifulSoup(html.text, "html.parser")
        findReferences = bsObj.findAll('span', {'class':'reference-text'})
        href = BeautifulSoup(str(findReferences), "html.parser")
        references = href.findAll('a', href=True)
        links = [a["href"] for a in href.find_all("a", href=True)]

        # Classify links
        wikiarticle = re.findall("\/wiki(!\/Special:BookSources)", links) # All wikipedia links ecxept books
        books = re.findall("books\.google\.com|books|\d\d\d-\d-\d\d\d-\d\d\d\d\d-\d", links) # All Books
        web = re.findall("web\.archive\.org", links) # All archived web pages

        # Safe Links in file
        outputfile = open("wikirefs.txt", "a")
        print(wikiarticle, file=outputfile)
        print(books, file=outputfile)
        print(web, file=outputfile)
        outputfile.close()

    else:
        print("Error: Please enter a valid Wikipedia URL")
